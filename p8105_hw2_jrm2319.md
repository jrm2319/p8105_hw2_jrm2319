Homework 2
================

### **Problem 1**

Loading in data and clean variable names:

``` r
library(readr)
library(dplyr)
```

    ## 
    ## Attaching package: 'dplyr'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     filter, lag

    ## The following objects are masked from 'package:base':
    ## 
    ##     intersect, setdiff, setequal, union

``` r
nyc_subway = read.csv("./data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv")
```

Retain specified variables

``` r
nyc_subway = select(nyc_subway, Line, Station.Name, Station.Latitude, Station.Longitude, Route1:Route11, Entrance.Type, Entry, Vending, ADA)
```

Modify ENTRY variable

``` r
nyc_subway$Entry.Logical = ifelse(nyc_subway$Entry == "YES", TRUE, FALSE)
```

**About this data set:**

This data set is called “nyc_subway” and contains the following
variables: line, station name, station latitude, station longitude,
route (1-11), entrance type, entry, vending, and ADA compliance.

I began by loading in the data and viewing it, I did not provide that in
the output document given the data set is large. Then, I retained the
variables listed above in the data set using the ‘select’ function.
Finally, I created a new variable, Entry.logical. This new variable
takes the Entry variable values and modifies the new variable to be
True/False. I chose to make a new variable in this case to ensure the
function was being run/used correctly without making permanent changes
to the Entry variable.

The data set has 20 variables and 1,868 observations. This data set
would be considered tidy because the columns are variables and the rows
are observations and every value has a cell.

**Data set questions:**

There are **465** distinct stations in this data set, this consists of
stations with different lines and station names.

``` r
distinct_station = distinct(nyc_subway, Line, Station.Name)
count(distinct_station)
```

    ##     n
    ## 1 465

There are **468** stations that are ADA compliant.

``` r
ADA_compliant = filter(nyc_subway, ADA == TRUE)
count(ADA_compliant)
```

    ##     n
    ## 1 468

There are **69** station entrances/exits without vending that allow
entrance.

``` r
novending_yesentry = filter(nyc_subway, Vending == "NO", Entry == "YES")
count(novending_yesentry)
```

    ##    n
    ## 1 69

**Reformatting data:**

### **Problem 2**

Importing data from excel file

``` r
library(readxl)
library(tidyr)

trash_wheel = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Mr. Trash Wheel")
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

Cleaning data

``` r
trash_wheel = 
  janitor::clean_names(trash_wheel) %>%
  select(dumpster, month, year, date, weight_tons, volume_cubic_yards, plastic_bottles, polystyrene, cigarette_butts, glass_bottles, plastic_bags, wrappers, sports_balls, homes_powered) %>%
  rename(weight = weight_tons, volume = volume_cubic_yards) %>% 
  drop_na(dumpster)


trash_wheel$sports_balls = round(trash_wheel$sports_balls)
trash_wheel$sports_balls = as.integer(trash_wheel$sports_balls)
trash_wheel$year = as.numeric(trash_wheel$year)

trash_wheel$wheel_id = "TW"
```

*Professor Trash Wheel Data*

Importing data from excel file

``` r
prof_trash_wheel = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Professor Trash Wheel")
```

Cleaning Data

``` r
prof_trash_wheel = 
  janitor::clean_names(prof_trash_wheel) %>%
  rename(weight = weight_tons, volume = volume_cubic_yards) %>% 
  drop_na(dumpster)
  

prof_trash_wheel$wheel_id = "PTW"
```

*Gwynnda Data*

Import data

``` r
gwynnda_trash_wheel = read_excel("./data/202409 Trash Wheel Collection Data.xlsx", sheet = "Gwynnda Trash Wheel")
```

Cleaning Data

``` r
gwynnda_trash_wheel = 
  janitor::clean_names(gwynnda_trash_wheel) %>%
  rename(weight = weight_tons, volume = volume_cubic_yards) %>% 
  drop_na(dumpster)

gwynnda_trash_wheel$wheel_id = "GTW"
```

Combine the data sets

``` r
merged_trash_wheel = bind_rows(trash_wheel, prof_trash_wheel, gwynnda_trash_wheel)
head(merged_trash_wheel)
```

    ## # A tibble: 6 × 15
    ##   dumpster month  year date                weight volume plastic_bottles
    ##      <dbl> <chr> <dbl> <dttm>               <dbl>  <dbl>           <dbl>
    ## 1        1 May    2014 2014-05-16 00:00:00   4.31     18            1450
    ## 2        2 May    2014 2014-05-16 00:00:00   2.74     13            1120
    ## 3        3 May    2014 2014-05-16 00:00:00   3.45     15            2450
    ## 4        4 May    2014 2014-05-17 00:00:00   3.1      15            2380
    ## 5        5 May    2014 2014-05-17 00:00:00   4.06     18             980
    ## 6        6 May    2014 2014-05-20 00:00:00   2.71     13            1430
    ## # ℹ 8 more variables: polystyrene <dbl>, cigarette_butts <dbl>,
    ## #   glass_bottles <dbl>, plastic_bags <dbl>, wrappers <dbl>,
    ## #   sports_balls <int>, homes_powered <dbl>, wheel_id <chr>

Answering questions

``` r
dump_total = merged_trash_wheel %>% 
  filter(wheel_id == "PTW")
dump_total = sum(dump_total$weight,na.rm=TRUE)
dump_total
```

    ## [1] 246.74

``` r
cigs_total = merged_trash_wheel %>% 
  filter(wheel_id == "GTW", year ==2022, month == "June")

cigs_total = sum(cigs_total$cigarette_butts, na.rm=TRUE)
cigs_total
```

    ## [1] 18120

The data set has 1033 observations and one key variables include
dumpster number, year, and wheel_id. The total weight of trash collected
by Professor Trash Wheel is 246.74 tons. The total number of cigarette
butts collected by Gwynnda in June 2022 was 18120.

### **Problem 3**

Import data

``` r
baker_df = read.csv("./data/gbb_datasets/bakers.csv") %>% 
    rename(baker = Baker.Name)
bakes_df = read.csv("./data/gbb_datasets/bakes.csv") %>% 
  rename(series = Series, episode = Episode, baker = Baker)
head(bakes_df)
```

    ##   series episode     baker
    ## 1      1       1   Annetha
    ## 2      1       1     David
    ## 3      1       1       Edd
    ## 4      1       1 Jasminder
    ## 5      1       1  Jonathan
    ## 6      1       1       Lea
    ##                                               Signature.Bake
    ## 1       Light Jamaican Black Cakewith Strawberries and Cream
    ## 2                                      Chocolate Orange Cake
    ## 3                           Caramel Cinnamon and Banana Cake
    ## 4             Fresh Mango and Passion Fruit Hummingbird Cake
    ## 5               Carrot Cake with Lime and Cream Cheese Icing
    ## 6 Cranberry and Pistachio Cakewith Orange Flower Water Icing
    ##                                                                                                     Show.Stopper
    ## 1                                       Red, White & Blue Chocolate Cake with Cigarellos, Fresh Fruit, and Cream
    ## 2 Black Forest Floor Gateauxwith Moulded Chocolate Leaves, Fallen Fruitand Chocolate Mushrooms Moulded from eggs
    ## 3                                                                                                            N/A
    ## 4                                                                                                            N/A
    ## 5                                                   Three Tiered White and Dark Chocolate with Almond and Cherry
    ## 6                                        Raspberries and Cream filled Chocolatewith Chocolate-dipped Fresh Fruit

``` r
results_df = read.csv("./data/gbb_datasets/results.csv", header = TRUE, skip = 2)
head(results_df)
```

    ##   series episode     baker technical result
    ## 1      1       1   Annetha         2     IN
    ## 2      1       1     David         3     IN
    ## 3      1       1       Edd         1     IN
    ## 4      1       1 Jasminder        NA     IN
    ## 5      1       1  Jonathan         9     IN
    ## 6      1       1    Louise        NA     IN

I imported the three data frames to be merged. First, I adjusted the
variable name “baker” to be consist across all the data frames, since
this will be the variable I will use to merge the three data frames.
